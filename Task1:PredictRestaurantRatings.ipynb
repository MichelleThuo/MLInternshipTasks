{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNywUAaNZI23b4lihNUpB4f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichelleThuo/MLInternshipTasks/blob/main/Task1%3APredictRestaurantRatings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessary libraries"
      ],
      "metadata": {
        "id": "zfgv07F07wb2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FX5dv8gH6dCi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Data Preprocessing"
      ],
      "metadata": {
        "id": "9TXOXWge77P2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "# Dataset .csv is the actual file path of the dataset\n",
        "data = pd.read_csv('Dataset .csv')\n",
        "\n",
        "# Explore the dataset\n",
        "# Display the first five rows of the dataset\n",
        "print(data.head())\n",
        "# Print summary information about the dataset (data types and non-null counts)\n",
        "print(data.info())\n",
        "# Generate descriptive statistics for numerical columns\n",
        "print(data.describe())\n",
        "\n",
        "# Identify the target variable and features\n",
        "# Assuming 'Aggregate rating' is the column for ratings and the rest are features\n",
        "target = 'Aggregate rating'\n",
        "# Drop the target column to isolate the feature set\n",
        "features = data.drop(columns=[target])\n",
        "\n",
        "# Split features into numerical and categorical columns\n",
        "# This will help apply different preprocessing techniques to each type\n",
        "numerical_features = features.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = features.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "# Define preprocessing for numerical data (imputing missing values and scaling)\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),  # Replace missing values with the mean\n",
        "    ('scaler', StandardScaler())  # Standardize numerical features to have mean=0 and variance=1\n",
        "])\n",
        "\n",
        "# Define preprocessing for categorical data (imputing missing values and encoding)\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Replace missing values with the most frequent value\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-hot encode categorical variables\n",
        "])\n",
        "\n",
        "# Combine preprocessing steps into a single column transformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),  # Apply numerical transformations\n",
        "        ('cat', categorical_transformer, categorical_features)  # Apply categorical transformations\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RY6IlCCk66hg",
        "outputId": "50975382-1e64-4b1f-c6a6-ec7ee00947ad"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Restaurant ID         Restaurant Name  Country Code              City  \\\n",
            "0        6317637        Le Petit Souffle           162       Makati City   \n",
            "1        6304287        Izakaya Kikufuji           162       Makati City   \n",
            "2        6300002  Heat - Edsa Shangri-La           162  Mandaluyong City   \n",
            "3        6318506                    Ooma           162  Mandaluyong City   \n",
            "4        6314302             Sambo Kojin           162  Mandaluyong City   \n",
            "\n",
            "                                             Address  \\\n",
            "0  Third Floor, Century City Mall, Kalayaan Avenu...   \n",
            "1  Little Tokyo, 2277 Chino Roces Avenue, Legaspi...   \n",
            "2  Edsa Shangri-La, 1 Garden Way, Ortigas, Mandal...   \n",
            "3  Third Floor, Mega Fashion Hall, SM Megamall, O...   \n",
            "4  Third Floor, Mega Atrium, SM Megamall, Ortigas...   \n",
            "\n",
            "                                     Locality  \\\n",
            "0   Century City Mall, Poblacion, Makati City   \n",
            "1  Little Tokyo, Legaspi Village, Makati City   \n",
            "2  Edsa Shangri-La, Ortigas, Mandaluyong City   \n",
            "3      SM Megamall, Ortigas, Mandaluyong City   \n",
            "4      SM Megamall, Ortigas, Mandaluyong City   \n",
            "\n",
            "                                    Locality Verbose   Longitude   Latitude  \\\n",
            "0  Century City Mall, Poblacion, Makati City, Mak...  121.027535  14.565443   \n",
            "1  Little Tokyo, Legaspi Village, Makati City, Ma...  121.014101  14.553708   \n",
            "2  Edsa Shangri-La, Ortigas, Mandaluyong City, Ma...  121.056831  14.581404   \n",
            "3  SM Megamall, Ortigas, Mandaluyong City, Mandal...  121.056475  14.585318   \n",
            "4  SM Megamall, Ortigas, Mandaluyong City, Mandal...  121.057508  14.584450   \n",
            "\n",
            "                           Cuisines  ...          Currency Has Table booking  \\\n",
            "0        French, Japanese, Desserts  ...  Botswana Pula(P)               Yes   \n",
            "1                          Japanese  ...  Botswana Pula(P)               Yes   \n",
            "2  Seafood, Asian, Filipino, Indian  ...  Botswana Pula(P)               Yes   \n",
            "3                   Japanese, Sushi  ...  Botswana Pula(P)                No   \n",
            "4                  Japanese, Korean  ...  Botswana Pula(P)               Yes   \n",
            "\n",
            "  Has Online delivery Is delivering now Switch to order menu Price range  \\\n",
            "0                  No                No                   No           3   \n",
            "1                  No                No                   No           3   \n",
            "2                  No                No                   No           4   \n",
            "3                  No                No                   No           4   \n",
            "4                  No                No                   No           4   \n",
            "\n",
            "   Aggregate rating  Rating color Rating text Votes  \n",
            "0               4.8    Dark Green   Excellent   314  \n",
            "1               4.5    Dark Green   Excellent   591  \n",
            "2               4.4         Green   Very Good   270  \n",
            "3               4.9    Dark Green   Excellent   365  \n",
            "4               4.8    Dark Green   Excellent   229  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9551 entries, 0 to 9550\n",
            "Data columns (total 21 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   Restaurant ID         9551 non-null   int64  \n",
            " 1   Restaurant Name       9551 non-null   object \n",
            " 2   Country Code          9551 non-null   int64  \n",
            " 3   City                  9551 non-null   object \n",
            " 4   Address               9551 non-null   object \n",
            " 5   Locality              9551 non-null   object \n",
            " 6   Locality Verbose      9551 non-null   object \n",
            " 7   Longitude             9551 non-null   float64\n",
            " 8   Latitude              9551 non-null   float64\n",
            " 9   Cuisines              9542 non-null   object \n",
            " 10  Average Cost for two  9551 non-null   int64  \n",
            " 11  Currency              9551 non-null   object \n",
            " 12  Has Table booking     9551 non-null   object \n",
            " 13  Has Online delivery   9551 non-null   object \n",
            " 14  Is delivering now     9551 non-null   object \n",
            " 15  Switch to order menu  9551 non-null   object \n",
            " 16  Price range           9551 non-null   int64  \n",
            " 17  Aggregate rating      9551 non-null   float64\n",
            " 18  Rating color          9551 non-null   object \n",
            " 19  Rating text           9551 non-null   object \n",
            " 20  Votes                 9551 non-null   int64  \n",
            "dtypes: float64(3), int64(5), object(13)\n",
            "memory usage: 1.5+ MB\n",
            "None\n",
            "       Restaurant ID  Country Code    Longitude     Latitude  \\\n",
            "count   9.551000e+03   9551.000000  9551.000000  9551.000000   \n",
            "mean    9.051128e+06     18.365616    64.126574    25.854381   \n",
            "std     8.791521e+06     56.750546    41.467058    11.007935   \n",
            "min     5.300000e+01      1.000000  -157.948486   -41.330428   \n",
            "25%     3.019625e+05      1.000000    77.081343    28.478713   \n",
            "50%     6.004089e+06      1.000000    77.191964    28.570469   \n",
            "75%     1.835229e+07      1.000000    77.282006    28.642758   \n",
            "max     1.850065e+07    216.000000   174.832089    55.976980   \n",
            "\n",
            "       Average Cost for two  Price range  Aggregate rating         Votes  \n",
            "count           9551.000000  9551.000000       9551.000000   9551.000000  \n",
            "mean            1199.210763     1.804837          2.666370    156.909748  \n",
            "std            16121.183073     0.905609          1.516378    430.169145  \n",
            "min                0.000000     1.000000          0.000000      0.000000  \n",
            "25%              250.000000     1.000000          2.500000      5.000000  \n",
            "50%              400.000000     2.000000          3.200000     31.000000  \n",
            "75%              700.000000     2.000000          3.700000    131.000000  \n",
            "max           800000.000000     4.000000          4.900000  10934.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Model Selection"
      ],
      "metadata": {
        "id": "-m493IC-8wtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selected the regression model\n",
        "# Uncomment the model you want to use\n",
        "model = LinearRegression()\n",
        "# model = DecisionTreeRegressor(random_state=42)\n",
        "# model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Create and compile the full pipeline including preprocessing and model\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('model', model)])  # Combine preprocessor and model into a single pipeline"
      ],
      "metadata": {
        "id": "9a5reb0z7LRd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Training and Evaluation"
      ],
      "metadata": {
        "id": "q5YEWC5g8zaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "# 80% training data, 20% testing data for evaluation\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, data[target], test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the model to the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance using Mean Squared Error and R-squared\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f'Mean Squared Error (MSE): {mse}') # Lower values are better\n",
        "print(f'R-squared: {r2}') # Values closer to 1 are better"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daqWelIY7aOX",
        "outputId": "b646a0c3-ab0e-4aa5-9c22-3997cbe58577"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 0.09178572062263937\n",
            "R-squared: 0.9596742858037922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Feature Interpretation"
      ],
      "metadata": {
        "id": "rti2ULil88Xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Interpret the model's results\n",
        "# Feature importances for tree-based models like DecisionTreeRegressor or RandomForestRegressor\n",
        "if hasattr(model, 'feature_importances_'):\n",
        "    feature_importances = model.feature_importances_\n",
        "    # Combine numerical and categorical feature names for interpretability\n",
        "    feature_names = numerical_features.tolist() + list(pipeline.named_steps['preprocessor'].transformers_[1][1].named_steps['onehot'].get_feature_names_out(categorical_features))\n",
        "    feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
        "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    # Plot the most influential features\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
        "    plt.xlabel('Importance')\n",
        "    plt.ylabel('Feature')\n",
        "    plt.title('Feature Importances')\n",
        "    plt.gca().invert_yaxis()  # Reverse the y-axis for better visibility\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Most influential features:\")\n",
        "    print(feature_importance_df.head(10))  # Display the top 10 features by importance\n",
        "else:\n",
        "    print(\"The selected model does not provide feature importances.\")\n",
        "\n",
        "# For LinearRegression, display coefficients to interpret the model\n",
        "if isinstance(model, LinearRegression):\n",
        "    coefficients = model.coef_\n",
        "    # Combine numerical and categorical feature names for interpretability\n",
        "    feature_names = numerical_features.tolist() + list(pipeline.named_steps['preprocessor'].transformers_[1][1].named_steps['onehot'].get_feature_names_out(categorical_features))\n",
        "    coef_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefficients})\n",
        "    coef_df = coef_df.sort_values(by='Coefficient', key=abs, ascending=False)  # Sort by absolute value of coefficients\n",
        "\n",
        "    print(\"Most influential features:\")\n",
        "    print(coef_df.head(10))  # Display the top 10 features by coefficient"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPGjC8U87oMl",
        "outputId": "47b706eb-c9bb-41ea-de10-2846b5663860"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The selected model does not provide feature importances.\n",
            "Most influential features:\n",
            "                                                 Feature  Coefficient\n",
            "7801   Address_36, Food Court, 2nd Floor, Pacific Mal...     1.264945\n",
            "17175                              Rating text_Not rated    -1.150447\n",
            "17170                                 Rating color_White    -1.150447\n",
            "10880  Address_K 11, Som Vihar Apartments, R K Puram,...     1.129207\n",
            "9913    Address_E-586, Greater Kailash (GK) 2, New Delhi    -1.091802\n",
            "7075   Address_2, Ground Floor, North West Avenue, Pu...    -1.047211\n",
            "7719   Address_32, Defence Colony Market, Defence Col...    -1.043531\n",
            "9919   Address_E-778, Market 2, Chittaranjan Park, Ne...     1.024175\n",
            "10560  Address_Ground Floor, Shipra Mall, Indirapuram...     0.983575\n",
            "8381   Address_67, 2nd Floor, Food Court, Moments Mal...    -0.982331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Displaying a few actual vs. predicted ratings"
      ],
      "metadata": {
        "id": "DcAxvKs1HniC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comparison_df = pd.DataFrame({'Actual Rating': y_test, 'Predicted Rating': y_pred})\n",
        "print(comparison_df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0izIPkK-T6X",
        "outputId": "ecddead5-8051-43bf-9469-f0f2c00b47d3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Actual Rating  Predicted Rating\n",
            "4731            2.1          2.215404\n",
            "1468            4.1          3.875280\n",
            "9037            3.2          2.889494\n",
            "7866            4.4          3.973292\n",
            "5570            3.5          3.048742\n",
            "5613            0.0          0.372515\n",
            "7751            3.2          2.911395\n",
            "1662            0.0          0.292812\n",
            "8592            3.6          3.043831\n",
            "2164            4.0          4.076226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Limitations and Future Improvements\n",
        "## 1. Handling Missing Values\n",
        "While we used SimpleImputer to handle missing values, we should consider whether mean imputation is appropriate, especially for skewed distributions. Future work could explore more sophisticated imputation methods (e.g., KNN imputation) or model-based imputation.\n",
        "\n",
        "## 2. Potential Overfitting\n",
        "The chosen model may overfit if it is too complex, especially on datasets with high variance. Cross-validation techniques could be implemented to validate the model's performance across different subsets of data.\n",
        "\n",
        "## 3. Feature Selection\n",
        "The model might include irrelevant features that do not contribute significantly to predictions. Techniques like Recursive Feature Elimination (RFE) or regularization methods (Lasso, Ridge) could help select more relevant features.\n",
        "\n",
        "## 4. Advanced Models\n",
        "Explore more complex models such as Gradient Boosting or ensemble methods to improve prediction accuracy and robustness.\n",
        "\n",
        "## 5. Model Interpretability\n",
        "For models like Random Forest or Gradient Boosting, feature importances could help interpret results, but advanced techniques like SHAP or LIME could provide better insights into model predictions."
      ],
      "metadata": {
        "id": "Gw3vZn1fGVR_"
      }
    }
  ]
}